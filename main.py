import os
import pdfplumber
import pytesseract
from PIL import Image
import pandas as pd
import re
from collections import Counter
from datetime import datetime

# ğŸ§¹ Remove leading time/date (supports comma, dash, time, AM/PM, etc.)
def clean_leading_datetime(text):
    text = text.strip()

    # Remove optional commas/dashes/spaces before time
    text = re.sub(r'^[\s,â€“-]*\d{1,2}:\d{2}(:\d{2})?\s*(AM|PM|am|pm|giá»|sÃ¡ng|chiá»u)?\s*', '', text)

    # Remove date formats like: NgÃ y 15/04/2020, 2020-04-15, 15-04-2020
    text = re.sub(r'^[\s,â€“-]*(NgÃ y\s+)?\d{1,2}[-/]\d{1,2}[-/]\d{2,4}\s*', '', text)
    text = re.sub(r'^[\s,â€“-]*\d{4}[-/]\d{2}[-/]\d{2}\s*', '', text)

    return text.strip()

# ğŸ§¹ Remove taglines like "NÃ³ng nháº¥t hÃ´m nay:"
def clean_news_tagline(text):
    return re.sub(r'^(NÃ³ng nháº¥t hÃ´m nay|Tin má»›i nháº¥t|Cáº­p nháº­t):\s*', '', text, flags=re.IGNORECASE)

# ğŸ“ Folder containing PDFs
pdf_folder = '/home/trongan93/Projects/covid-doc-feature/data/2020'

# ğŸ“‹ Store results
data = []

# ğŸ” Loop through all PDF files
for filename in os.listdir(pdf_folder):
    if filename.endswith('.pdf'):
        filepath = os.path.join(pdf_folder, filename)
        print(f"ğŸ“„ Äang xá»­ lÃ½: {filename}")

        try:
            with pdfplumber.open(filepath) as pdf:
                text = ''
                for page in pdf.pages:
                    page_text = page.extract_text()

                    # OCR fallback
                    if not page_text:
                        img_obj = page.to_image(resolution=300)
                        page_text = pytesseract.image_to_string(img_obj.original, lang='vie')

                    text += page_text + '\n'

                # ----- TITLE -----
                lines = [line.strip() for line in text.split('\n') if line.strip()]
                title_candidates = [line for line in lines if (
                    line.isupper() or line.istitle()
                ) and 10 < len(line) < 120]

                if title_candidates:
                    title = title_candidates[0]
                elif lines:
                    title = lines[0]
                else:
                    title = 'KhÃ´ng tÃ¬m tháº¥y tiÃªu Ä‘á»'

                # Clean title
                title = clean_leading_datetime(title)
                title = clean_news_tagline(title)

                # ----- DATE -----
                date_patterns = [
                    r'(\d{4}-\d{2}-\d{2})',
                    r'(\d{2}/\d{2}/\d{4})',
                    r'NgÃ y\s+(\d{1,2})\s+thÃ¡ng\s+(\d{1,2})\s+nÄƒm\s+(\d{4})'
                ]

                date = 'KhÃ´ng tÃ¬m tháº¥y ngÃ y'
                for pattern in date_patterns:
                    match = re.search(pattern, text)
                    if match:
                        if len(match.groups()) == 1:
                            date = match.group(1)
                        else:
                            d, m, y = match.groups()
                            date = f"{y}-{int(m):02d}-{int(d):02d}"
                        break

                # ----- SUMMARY -----
                raw_sentences = text.split('ã€‚')
                clean_sentences = []

                for sentence in raw_sentences:
                    sentence = clean_leading_datetime(sentence)
                    sentence = clean_news_tagline(sentence)
                    clean_sentences.append(sentence)
                    if len(clean_sentences) == 2:
                        break

                summary = 'ã€‚'.join(clean_sentences) + 'ã€‚'

                # ----- KEYWORDS -----
                words = re.findall(r'\b\w{4,}\b', text.lower())
                common_words = Counter(words).most_common(5)
                keywords = ', '.join([w[0] for w in common_words])

                # ----- CATEGORY -----
                categories = {
                    'váº¯c-xin': 'váº¯c-xin|tiÃªm chá»§ng',
                    'há»— trá»£ cÃ´ng nhÃ¢n': 'há»— trá»£ cÃ´ng nhÃ¢n|trá»£ cáº¥p',
                    'tuyÃªn truyá»n phÃ²ng dá»‹ch': 'tuyÃªn truyá»n|giÃ¡o dá»¥c phÃ²ng dá»‹ch',
                    'doanh nghiá»‡p phÃ²ng dá»‹ch': 'doanh nghiá»‡p|phÃ²ng chá»‘ng dá»‹ch',
                    'hoáº¡t Ä‘á»™ng cÃ´ng Ä‘oÃ n': 'hoáº¡t Ä‘á»™ng cÃ´ng Ä‘oÃ n|cÃ´ng Ä‘oÃ n'
                }

                category_vn = None
                for cat, pattern in categories.items():
                    if re.search(pattern, text, re.IGNORECASE):
                        category_vn = cat
                        break

                if not category_vn:
                    keyword_list = [w for w, _ in Counter(words).most_common(20)
                                    if w not in ['cÃ´ng', 'ngÆ°á»i', 'viá»‡c', 'phÃ²ng', 'dá»‹ch', 'bá»‡nh']]
                    category_vn = f"Tá»± Ä‘á»™ngåˆ†é¡: {keyword_list[0]}" if keyword_list else 'khÃ¡c'

                # ----- WORKER-RELATED -----
                worker_related = 'cÃ´ng nhÃ¢n' in text.lower()

                # ----- SAVE RESULT -----
                data.append({
                    'æ—¥æœŸ': date,
                    'è¶Šå—æ–‡æ¨™é¡Œ': title,
                    'è¶Šå—æ–‡æ‘˜è¦': summary,
                    'è¶Šå—æ–‡é—œéµå­—': keywords,
                    'è¶Šå—æ–‡åˆ†é¡': category_vn,
                    'æ˜¯å¦èˆ‡å·¥äººç›¸é—œ': worker_related
                })

        except Exception as e:
            print(f"âŒ Lá»—i khi xá»­ lÃ½ {filename}: {e}")

# ----- EXPORT TO CSV -----
timestamp = datetime.now().strftime('%Y%m%d_%H%M')
output_path = f'æ–°èåˆ†æçµæœ_è¶Šæ–‡ç‰ˆ_{timestamp}.csv'
df = pd.DataFrame(data)
df.to_csv(output_path, index=False, encoding='utf-8-sig')
print(f"âœ… HoÃ n táº¥t! Káº¿t quáº£ Ä‘Æ°á»£c lÆ°u táº¡i: {output_path}")
