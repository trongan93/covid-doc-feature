import os
import pdfplumber
import pytesseract
from PIL import Image
import pandas as pd
import re
from collections import Counter
from datetime import datetime

# Ubuntu: Tesseract will be found automatically (no need to set path)

# Specify your PDF folder
pdf_folder = '/home/trongan93/Projects/covid-doc-feature/data/2023'

# Storage for results
data = []

# Process each PDF file
for filename in os.listdir(pdf_folder):
    if filename.endswith('.pdf'):
        filepath = os.path.join(pdf_folder, filename)
        print(f"ğŸ“ Processing: {filename}")

        try:
            with pdfplumber.open(filepath) as pdf:
                text = ''
                for page in pdf.pages:
                    page_text = page.extract_text()

                    # If no text found, use OCR
                    if not page_text:
                        img_obj = page.to_image(resolution=300)
                        page_text = pytesseract.image_to_string(img_obj.original, lang='vie')

                    text += page_text + '\n'

                # Extract title (use longest non-empty line)
                lines = [line.strip() for line in text.split('\n') if line.strip()]
                title = max(lines, key=len) if lines else 'KhÃ´ng tÃ¬m tháº¥y tiÃªu Ä‘á»'

                # Extract date
                date_match = re.search(r'(\d{4}-\d{2}-\d{2})', text)
                date = date_match.group(1) if date_match else 'KhÃ´ng tÃ¬m tháº¥y ngÃ y'

                # Summary (first 2 sentences)
                summary = 'ã€‚'.join(text.split('ã€‚')[:2]) + 'ã€‚'

                # Keywords (top 5 common long words)
                words = re.findall(r'\b\w{4,}\b', text.lower())
                common_words = Counter(words).most_common(5)
                keywords = ', '.join([w[0] for w in common_words])

                # Categorization
                categories = {
                    'váº¯c-xin': 'váº¯c-xin|tiÃªm chá»§ng',
                    'há»— trá»£ cÃ´ng nhÃ¢n': 'há»— trá»£ cÃ´ng nhÃ¢n|trá»£ cáº¥p',
                    'tuyÃªn truyá»n phÃ²ng dá»‹ch': 'tuyÃªn truyá»n|giÃ¡o dá»¥c phÃ²ng dá»‹ch',
                    'doanh nghiá»‡p phÃ²ng dá»‹ch': 'doanh nghiá»‡p|phÃ²ng chá»‘ng dá»‹ch',
                    'hoáº¡t Ä‘á»™ng cÃ´ng Ä‘oÃ n': 'hoáº¡t Ä‘á»™ng cÃ´ng Ä‘oÃ n|cÃ´ng Ä‘oÃ n'
                }

                category_vn = 'khÃ¡c'
                for cat, pattern in categories.items():
                    if re.search(pattern, text, re.IGNORECASE):
                        category_vn = cat
                        break

                worker_related = 'cÃ´ng nhÃ¢n' in text.lower()

                # Append result
                data.append({
                    'æ—¥æœŸ': date,
                    'è¶Šå—æ–‡æ¨™é¡Œ': title,
                    'è¶Šå—æ–‡æ‘˜è¦': summary,
                    'è¶Šå—æ–‡é—œéµå­—': keywords,
                    'è¶Šå—æ–‡åˆ†é¡': category_vn,
                    'æ˜¯å¦èˆ‡å·¥äººç›¸é—œ': worker_related
                })

        except Exception as e:
            print(f"âš ï¸ Error processing {filename}: {e}")

# Export results as CSV (UTF-8 for Vietnamese support)
timestamp = datetime.now().strftime('%Y%m%d_%H%M')
output_path = f'æ–°èåˆ†æçµæœ_è¶Šæ–‡ç‰ˆ_{timestamp}.csv'
df = pd.DataFrame(data)
df.to_csv(output_path, index=False, encoding='utf-8-sig')
print(f"âœ… åˆ†æå®Œæˆï¼Œçµæœå„²å­˜æ–¼ï¼š{output_path}")
